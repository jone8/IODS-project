install.packages(prettydoc)
install.packages("prettydoc")
"hello world"
lrn2014<- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt",
header=T, sep="\t")
str(lrn2014)
dim(lrn2014)
install.packages("dplyr")
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D06",  "D15", "D23", "D31")
surface_questions <- c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
deep_columns<- select(lrn2014, one_of(deep_questions))
lrn2014$deep <- rowMeans(deep_columns)
surface_columns <- select(lrn2014, one_of(surface_questions))
lrn2014$surf <- rowMeans(surface_columns)
strategic_columns <- select(lrn2014, one_of(strategic_questions))
lrn2014$stra <- rowMeans(strategic_columns)
View(lrn2014)
lrn14<- read.table("data/analysis_lrn2014_teksti.txt")
str(lrn14)
dim(lrn14)
summary(lrn14)
library(ggplot2)
library(GGally)
summary(lm(Points~Attitude,data=lrn14))
hei<-lm(Points~ Attitude, data=lrn14)
plot(hei)
summary(lm(points~Attitude,data=lrn14))
summary(lm(Points~attitude,data=lrn14))
summary(lm(Points~attitude,data=lrn14))
lrn14<- read.table("data/analysis_lrn2014_teksti.txt")
summary(lm(Points~attitude,data=lrn14))
new_data <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
str(new_data)
dim(new_data)
head(new_data, n = 20)
library(GGally)
library(ggplot2)
p <- ggpairs(new_data, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
print(p)
library(Hmisc)
describe(new_data)
lrn14<- read.table("data/analysis_lrn2014_teksti.txt")
str(lrn14)
dim(lrn14)
summary(lrn14)
dim(lrn14)
str(lrn14)
library(ggplot2)
library(GGally)
summary(lm(Points~Attitude,data=lrn14))
hei<-lm(Points~ Attitude, data=lrn14)
plot(hei)
qplot(Attitude, Points, data = lrn14) + geom_smooth(method = "lm")
my_model <- lm(Points ~ Age+ Attitude+stra, data = lrn14)
summary(my_model)
ggpairs(lrn14, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))
plot(lm(Points~Attitude, data=lrn14), which = c(1,2,5), par(mfrow=c(2,2)) )
plot(lm(Points~Attitude, data=lrn14), which = c(1,2,5), par(mfrow=c(2,2)) )
str(lrn14)
dim(lrn14)
-jee
lrn14<- read.table("data/analysis_lrn2014_teksti.txt")
str(lrn14)
dim(lrn14)
-jee
lrn14<- read.table("data/analysis_lrn2014_teksti.txt")
str(lrn14)
---
```{R}
---
```{r}
str(new_data)
dim(new_data)
head(new_data, n = 20)
```{r}
new_data <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
* The current dataset is a part of the course 'Introduction to Social Statistics' held by 'Kimmo Vehkalahti' in 'Fall 2014'.The study data were from the years 2014 to 2015 and it aimed to summarize the study behavior and approaches to learning in an international survey.
new_data <- read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",", header=TRUE)
* The current dataset is a part of the course 'Introduction to Social Statistics' held by 'Kimmo Vehkalahti' in 'Fall 2014'.The study data were from the years 2014 to 2015 and it aimed to summarize the study behavior and approaches to learning in an international survey.
65000*5
65000+65000+100000
230000*0,1
230000*0.1
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt")"
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt")"
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt")
View(data)
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", sep=",")
View(data)
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", sep=",", header=T)
View(data)
alc<- read.csv2("data/create_alc")
alc<- read.csv2("data/create_alc.csv")
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", sep=",", header=T)
alc<- read.csv2("data/create_alc.csv")
getwd()
alc<- read.csv2("data/alc.csv")
View(alc)
#Jone 8
# 12.11.2018
#viikko3
setwd("C:\\Users\\pingv\\Documents\\GitHub\\IODS-project")
student_mat <- read.csv("student-mat.csv", sep=";")
student_por<- read.csv2("student-por.csv")
str(student_mat)
str(student_por)
dim(student_mat)
dim(student_por)
#3
library(dplyr)
colnames(student_mat)
colnames(student_por)
#4
# voi olla vastannut eri tavoin eri kysymyksiin, yhdistää näiden mukaan.
join_by= c( "school", "sex", "age", "address",
"famsize", "Pstatus", "Medu", "Fedu", "Mjob", "Fjob", "reason",
"nursery","internet")
joined_data<-inner_join(student_mat, student_por, by= join_by,
suffix= c("math", "por"))
str(joined_data)
dim(joined_data)
#5
alc <- select(joined_data, one_of(join_by))
# the columns in the datasets which were not used for joining the data
notjoined_columns <- colnames(student_mat)[!colnames(student_mat) %in% join_by]
# print out the columns not used for joining
notjoined_columns
# for every column name not used for joining...
for(column_name in notjoined_columns) {
# select two columns from 'math_por' with the same original name
two_columns <- select(joined_data, starts_with(column_name))
# select the first column vector of those two columns
first_column <- select(two_columns, 1)[[1]]
# if that first column vector is numeric...
if(is.numeric(first_column)) {
# take a rounded average of each row of the two columns and
# add the resulting vector to the alc data frame
alc[column_name] <- round(rowMeans(two_columns))
} else { # else if it's not numeric...
# add the first column vector to the alc data frame
alc[column_name] <- first_column
}
}
alc
#6.
alc_days<-select(alc, "Dalc", "Walc")
alc$alc_use<- rowMeans(alc_days)
#alc <- mutate(alc, alc_use2 = (Dalc + Walc)/2)
alc$high_use<- alc$alc_use>2
#alc <- mutate(alc, high_use2 = alc_use2 > 2)
#7
glimpse(alc)
getwd()
write.csv2(alc, file="data/alc.csv", row.names = F)
testi<-read.csv2("data/alc.csv")
alc<- read.csv2("data/alc.csv")
View(alc)
data<-read.table("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/alc.txt", sep=",", header=T)
View(data)
student_mat <- read.csv("student-mat.csv", sep=";")
student_por<- read.csv2("student-por.csv")
View(student_mat)
View(student_por)
View(alc)
View(data)
g1 <- ggplot(alc, aes(x=high_use, y=famrel, col = sex))
library(ggplot2)
g1 <- ggplot(alc, aes(x=high_use, y=famrel, col = sex))
g1 + geom_boxplot() + ylab("Family relationships")+ xlab("High usage") + ggtitle("Family relationships vs high usage of alcohol")
?geom_bar
?ggplot
library(MASS)
str(Boston)
dim(Boston)
plot(Boston)
summary(Boston)
scaled_data<- scale(Boston)
View(scaled_data)
summary(scaled_data)
?data.frame
?cut
?cut
library(MASS)
str(Boston)
dim(Boston)
plot(Boston)
summary(Boston)
scaled_data<- scale(Boston)
summary(scaled_data)
crime<- cut()
class(scaled_data)
View(scaled_data)
scaled_crim <- boston_scaled$crim
boston_scaled<- scale(Boston)
scaled_crim <- boston_scaled$crim
summary(boston_scaled)
scaled_crim <- boston_scaled$crim
as.data.frame(boston_scaled)
scaled_crim <- boston_scaled$crim
boston>scaled<-as.data.frame(boston_scaled)
boston_scaled<-as.data.frame(boston_scaled)
scaled_crim <- boston_scaled$crim
bins <- quantile(scaled_crim)
?cut
crime<- cut(scaled_crim, breaks= bins, labels
=c("low", "med_low", "med_high", "high"))
crime
crime<- cut(scaled_crim, breaks= bins, include.lowest=T,labels
=c("low", "med_low", "med_high", "high"))
table(crime)
boston_scaled <- dplyr::select(boston_scaled, -crim)
boston_scaled <- data.frame(boston_scaled, crime)
View(boston_scaled)
?sample
?sample()
n <- nrow(boston_scaled)
ind <- sample(n,  size = n * 0.8)
train<-boston_scaled[ind,]
test<- boston_scaled[-ind,]
